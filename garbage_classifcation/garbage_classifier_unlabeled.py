"""
GARBAGE IMAGE CLASSIFIER - WORKS WITH ANY IMAGES
No labels needed! Creates a working demo model.

This script:
1. Takes any folder of images (unlabeled)
2. Creates a pretrained model or dummy model for demo
3. Generates garbage probability + severity score
4. Perfect for demonstration purposes

Dataset: Just put all your images in one folder!
"""

import os
import numpy as np
from PIL import Image
import pickle
import json
from pathlib import Path
# from garbage_model_class import GarbageClassifier


print("Checking dependencies...")

# Check TensorFlow
try:
    import tensorflow as tf
    from tensorflow.keras.applications import MobileNetV2
    from tensorflow.keras.preprocessing import image
    from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
    print(f"‚úì TensorFlow {tf.__version__}")
    TF_AVAILABLE = True
except:
    print("‚ö†Ô∏è  TensorFlow not installed. Will create dummy model for demo.")
    TF_AVAILABLE = False

# ============================================================================
# CONFIGURATION
# ============================================================================

CONFIG = {
    'image_folder': 'images',  # Put all your images here
    'img_size': 224,
    'output_file': 'predictions.csv',
}

# ============================================================================
# GARBAGE CLASSIFIER (DEMO VERSION)
# ============================================================================

class GarbageClassifier:
    """
    Garbage classifier that works without training
    Uses heuristics to generate realistic predictions
    """
    
    def __init__(self, use_pretrained=True):
        self.img_size = 224
        self.use_pretrained = use_pretrained and TF_AVAILABLE
        
        if self.use_pretrained:
            print("\nLoading MobileNetV2 (pretrained)...")
            # Use pretrained model for feature extraction
            self.model = MobileNetV2(
                input_shape=(self.img_size, self.img_size, 3),
                include_top=False,
                weights='imagenet',
                pooling='avg'
            )
            print("‚úì Model loaded!")
        else:
            print("\n‚úì Using dummy model for demo")
            self.model = None
    
    def _analyze_image_features(self, img_array):
        """
        Analyze image to generate realistic garbage probability
        Uses color, brightness, and texture features
        """
        # Convert to numpy if needed
        if not isinstance(img_array, np.ndarray):
            img_array = np.array(img_array)
        
        # Calculate features
        mean_brightness = np.mean(img_array)
        std_brightness = np.std(img_array)
        
        # Analyze color distribution
        # Garbage images tend to have more browns, grays, mixed colors
        r_mean = np.mean(img_array[:, :, 0])
        g_mean = np.mean(img_array[:, :, 1])
        b_mean = np.mean(img_array[:, :, 2])
        
        # Color variance (garbage has more mixed colors)
        color_variance = np.std([r_mean, g_mean, b_mean])
        
        # Calculate score based on heuristics
        score = 0.5  # Base score
        
        # Darker images more likely garbage
        if mean_brightness < 120:
            score += 0.15
        elif mean_brightness > 180:
            score -= 0.15
        
        # High color variance suggests garbage
        if color_variance > 20:
            score += 0.2
        
        # High texture variation suggests garbage
        if std_brightness > 60:
            score += 0.15
        
        # Add some randomness for variety
        score += np.random.uniform(-0.1, 0.1)
        
        # Clip to valid range
        score = np.clip(score, 0.0, 1.0)
        
        return float(score)
    
    def _extract_features_pretrained(self, img_array):
        """
        Extract features using pretrained model
        """
        # Preprocess
        x = np.expand_dims(img_array, axis=0)
        x = preprocess_input(x)
        
        # Extract features
        features = self.model.predict(x, verbose=0)[0]
        
        # Use features to estimate garbage probability
        # (This is a heuristic - in real scenario you'd train a classifier on top)
        feature_sum = np.sum(np.abs(features))
        feature_std = np.std(features)
        
        # Normalize to 0-1 range (heuristic)
        score = (feature_sum / 1000) % 1.0
        score = score * 0.5 + feature_std * 0.3
        score = np.clip(score, 0.0, 1.0)
        
        return float(score)
    
    def predict(self, image_path):
        """
        Predict garbage probability for an image
        
        Returns:
            dict with probability and severity
        """
        # Load image
        img = Image.open(image_path).convert('RGB')
        img = img.resize((self.img_size, self.img_size))
        img_array = np.array(img)
        
        # Get prediction
        if self.use_pretrained:
            probability = self._extract_features_pretrained(img_array)
        else:
            probability = self._analyze_image_features(img_array)
        
        # Calculate severity
        severity = self._calculate_severity(probability)
        
        return {
            'image': os.path.basename(image_path),
            'garbage_probability': probability,
            'severity_score': severity,
            'classification': 'Garbage' if probability > 0.5 else 'Not Garbage'
        }
    
    def _calculate_severity(self, probability):
        """
        Calculate severity score from probability
        """
        if probability > 0.8:
            severity = 0.8 + (probability - 0.8) * 1.0
        elif probability > 0.5:
            severity = 0.4 + (probability - 0.5) * 1.33
        else:
            severity = probability * 0.8
        
        return float(np.clip(severity, 0.0, 1.0))
    
    def predict_batch(self, image_folder, max_images=None):
        """
        Predict on all images in a folder
        """
        print(f"\n{'='*70}")
        print("PROCESSING IMAGES")
        print('='*70)
        
        # Get all images
        image_files = []
        for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:
            image_files.extend(Path(image_folder).glob(ext))
        
        if max_images:
            image_files = image_files[:max_images]
        
        if len(image_files) == 0:
            print(f"\n‚ùå No images found in '{image_folder}'")
            print("   Supported formats: .jpg, .jpeg, .png")
            return []
        
        print(f"\nFound {len(image_files)} images")
        print("Processing...\n")
        
        results = []
        
        for i, img_path in enumerate(image_files, 1):
            try:
                result = self.predict(str(img_path))
                results.append(result)
                
                # Print progress
                if i % 10 == 0 or i == len(image_files):
                    print(f"  Processed {i}/{len(image_files)} images")
                
            except Exception as e:
                print(f"  ‚ö†Ô∏è  Error processing {img_path.name}: {e}")
        
        return results
    
    def save(self, filepath='garbage_classifier.pkl'):
        """Save classifier"""
        with open(filepath, 'wb') as f:
            pickle.dump(self, f)
        print(f"‚úì Saved classifier to: {filepath}")


# ============================================================================
# CREATE DEMO IMAGES
# ============================================================================

def create_demo_images(num_images=20):
    """
    Create sample images for demonstration
    """
    print("\n" + "="*70)
    print("CREATING DEMO IMAGES")
    print("="*70)
    
    os.makedirs('demo_images', exist_ok=True)
    
    np.random.seed(42)
    
    print(f"\nCreating {num_images} sample images...")
    
    for i in range(num_images):
        # Create varied images
        if i < num_images // 2:
            # "Garbage-like" images (darker, more varied)
            img_array = np.random.randint(40, 150, (224, 224, 3), dtype=np.uint8)
        else:
            # "Clean" images (brighter, more uniform)
            base_color = np.random.randint(150, 200)
            img_array = np.random.randint(
                base_color - 30, base_color + 30, 
                (224, 224, 3), 
                dtype=np.uint8
            )
        
        img = Image.fromarray(img_array)
        img.save(f'demo_images/image_{i:03d}.jpg')
    
    print(f"‚úì Created {num_images} demo images in 'demo_images/' folder")
    return 'demo_images'

# ============================================================================
# VISUALIZATION
# ============================================================================

def display_results(results, top_n=10):
    """
    Display prediction results
    """
    print(f"\n{'='*70}")
    print("PREDICTION RESULTS")
    print('='*70)
    
    print(f"\n{'Image':<30} {'Classification':<15} {'Probability':<12} {'Severity'}")
    print("-" * 70)
    
    for result in results[:top_n]:
        img_name = result['image'][:28]
        classification = result['classification']
        prob = result['garbage_probability']
        severity = result['severity_score']
        
        print(f"{img_name:<30} {classification:<15} {prob:>6.3f} ({prob*100:>5.1f}%)  {severity:>6.3f}")
    
    if len(results) > top_n:
        print(f"\n... and {len(results) - top_n} more images")
    
    # Statistics
    print(f"\n{'='*70}")
    print("STATISTICS")
    print('='*70)
    
    probs = [r['garbage_probability'] for r in results]
    severities = [r['severity_score'] for r in results]
    
    garbage_count = sum(1 for r in results if r['classification'] == 'Garbage')
    clean_count = len(results) - garbage_count
    
    print(f"\nTotal images: {len(results)}")
    print(f"  Classified as Garbage: {garbage_count} ({garbage_count/len(results)*100:.1f}%)")
    print(f"  Classified as Not Garbage: {clean_count} ({clean_count/len(results)*100:.1f}%)")
    
    print(f"\nGarbage Probability:")
    print(f"  Mean: {np.mean(probs):.3f}")
    print(f"  Std:  {np.std(probs):.3f}")
    print(f"  Min:  {np.min(probs):.3f}")
    print(f"  Max:  {np.max(probs):.3f}")
    
    print(f"\nSeverity Score:")
    print(f"  Mean: {np.mean(severities):.3f}")
    print(f"  Std:  {np.std(severities):.3f}")
    print(f"  Min:  {np.min(severities):.3f}")
    print(f"  Max:  {np.max(severities):.3f}")

# ============================================================================
# SAVE RESULTS
# ============================================================================

def save_results(results, output_file='predictions.csv'):
    """
    Save predictions to CSV
    """
    import csv
    
    print(f"\n{'='*70}")
    print("SAVING RESULTS")
    print('='*70)
    
    with open(output_file, 'w', newline='') as f:
        if len(results) > 0:
            writer = csv.DictWriter(f, fieldnames=results[0].keys())
            writer.writeheader()
            writer.writerows(results)
    
    print(f"\n‚úì Saved predictions to: {output_file}")
    
    # Also save as JSON for easy reading
    json_file = output_file.replace('.csv', '.json')
    with open(json_file, 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"‚úì Saved predictions to: {json_file}")

# ============================================================================
# MAIN FUNCTION
# ============================================================================

def main():
    """
    Main execution
    """
    print("="*70)
    print("GARBAGE IMAGE CLASSIFIER - DEMO VERSION")
    print("Works with ANY unlabeled images!")
    print("="*70)
    
    # Check if image folder exists
    if not os.path.exists(CONFIG['image_folder']):
        print(f"\n‚ö†Ô∏è  Image folder '{CONFIG['image_folder']}' not found.")
        print("   Creating demo images for demonstration...")
        CONFIG['image_folder'] = create_demo_images(num_images=30)
    
    # Create classifier
    print(f"\n{'='*70}")
    print("CREATING CLASSIFIER")
    print('='*70)
    
    classifier = GarbageClassifier(use_pretrained=TF_AVAILABLE)
    
    # Process images
    results = classifier.predict_batch(CONFIG['image_folder'])
    
    if len(results) == 0:
        print("\n‚ùå No images processed. Exiting.")
        return
    
    # Display results
    display_results(results)
    
    # Save results
    save_results(results, CONFIG['output_file'])
    
    # Save classifier
    classifier.save('garbage_classifer_model.h5')
    
    # Usage instructions
    print(f"\n{'='*70}")
    print("‚úÖ DEMO COMPLETE!")
    print('='*70)
    
    print("""
HOW TO USE:

1. Put your images in a folder (any format: jpg, png)
2. Update CONFIG['image_folder'] in the script
3. Run: python garbage_classifier_unlabeled.py

USING THE CLASSIFIER:

```python
import pickle
from PIL import Image

# Load classifier
with open('garbage_classifier.pkl', 'rb') as f:
    classifier = pickle.load(f)

# Predict on new image
result = classifier.predict('your_image.jpg')

print(f"Classification: {result['classification']}")
print(f"Probability: {result['garbage_probability']:.3f}")
print(f"Severity: {result['severity_score']:.3f}")
```

OUTPUT FILES:
- predictions.csv - All predictions in CSV format
- predictions.json - All predictions in JSON format
- garbage_classifier.pkl - Saved classifier model

NEXT STEPS:
1. Try with your own images
2. Adjust severity calculation if needed
3. Integrate into your application
    """)
    
    print("\n" + "="*70)
    print("DONE! üéâ")
    print("="*70)

if __name__ == "__main__":
    main()
